{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport json\\nimport re'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#histogram of number of subwcribers\\n\\nchannels = pd.read_csv(\"data/df_channels_en.tsv\", sep = \"\\t\")\\ndisplay(channels)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram of categories\n",
    "\n",
    "channels = pd.read_csv(\"data/df_channels_en.tsv\", sep = \"\\t\")\n",
    "display(channels)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.hist(channels['subscribers_cc'], log=True, bins= 50)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.hist(channels['subscribers_cc'], log=True, bins= 50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import string\\n\\ndef is_collab(text):\\n    keywords = [\"collab\", \"collaboration\", \"ft.\", \"feat\", \"featuring\"]\\n    # Split the text into words and handle punctuation\\n    text = text.lower()\\n    words_in_text = text.translate(str.maketrans(\\'\\', \\'\\', string.punctuation)).split()\\n    \\n    \\n    for word in keywords:\\n        if word in words_in_text:\\n            return True\\n    return False'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import string\n",
    "\n",
    "def is_collab(text):\n",
    "    keywords = [\"collab\", \"collaboration\", \"ft.\", \"feat\", \"featuring\"]\n",
    "    # Split the text into words and handle punctuation\n",
    "    text = text.lower()\n",
    "    words_in_text = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    \n",
    "    \n",
    "    for word in keywords:\n",
    "        if word in words_in_text:\n",
    "            return True\n",
    "    return False\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\n!pip install pyspark'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "!pip install pyspark\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark import SparkContext\\nsc = SparkContext()\\n\\nfile_path = \"data/yt_metadata_en.jsonl\"\\nraw_data = sc.textFile(file_path)\\n\\ndataset = raw_data.map(lambda x: json.loads(x))\\n#dataset.persist()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "file_path = \"data/yt_metadata_en.jsonl\"\n",
    "raw_data = sc.textFile(file_path)\n",
    "\n",
    "dataset = raw_data.map(lambda x: json.loads(x))\n",
    "#dataset.persist()\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_count = dataset.count()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"total_count = dataset.count()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset.take(1)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dataset.take(1)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filtered_dataset_descr = dataset.filter(lambda x:is_collab(x.get(\"description\", \"\")))\\nfiltered_dataset_title = dataset.filter(lambda x:is_collab(x.get(\"title\", \"\")))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filtered_dataset_descr = dataset.filter(lambda x:is_collab(x.get(\"description\", \"\")))\n",
    "filtered_dataset_title = dataset.filter(lambda x:is_collab(x.get(\"title\", \"\")))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colab_count_descr = filtered_dataset_descr.count()\\ncolab_count_title = filtered_dataset_title.count()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"colab_count_descr = filtered_dataset_descr.count()\n",
    "colab_count_title = filtered_dataset_title.count()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(colab_count_descr/total_count * 100)\\nprint(colab_count_title/total_count * 100)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(colab_count_descr/total_count * 100)\n",
    "print(colab_count_title/total_count * 100)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filtered_dataset_descr.take(2)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"filtered_dataset_descr.take(2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_dataset_title.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sampled_dataset = dataset.sample(fraction = 0.001, withReplacement=False ,seed=42)\\n\\njson_data = sampled_dataset.collect()\\n\\nwith open(\"data/sampled_dataset.json\", \"w\") as f:\\n    json.dump(json_data, f)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"sampled_dataset = dataset.sample(fraction = 0.001, withReplacement=False ,seed=42)\n",
    "\n",
    "json_data = sampled_dataset.collect()\n",
    "\n",
    "with open(\"data/sampled_dataset.json\", \"w\") as f:\n",
    "    json.dump(json_data, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/11 20:16:10 WARN Utils: Your hostname, MacBook-Pro-de-Paul-2.local resolves to a loopback address: 127.0.0.1; using 192.168.1.33 instead (on interface en0)\n",
      "23/11/11 20:16:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/11 20:16:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "file_path = \"data/sampled_dataset.jsonl\" #\"data/yt_metadata_en.jsonl\"\n",
    "raw_data = sc.textFile(file_path)\n",
    "\n",
    "dataset = raw_data.map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  72602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_count = dataset.count()\n",
    "print(\"Number of rows: \", total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'categories': 'Film & Animation',\n",
       "  'channel_id': 'UCzWrhkg9eK5I8Bm3HfV-unA',\n",
       "  'crawl_date': '2019-10-31 20:19:30.784552',\n",
       "  'description': 'Lego City Police Lego Fireman Firetruck Cartoons about Lego for Children with a nice long video to keep the little ones entertained while learning and having fun. Thanks for watching!',\n",
       "  'dislike_count': 31.0,\n",
       "  'display_id': 'HNg8_Zzz5A8',\n",
       "  'duration': 1539,\n",
       "  'like_count': 114.0,\n",
       "  'tags': 'Lego city police,lego police,lego city,lego fireman,bomberos para niños,policia niños,lego movies,lego movies ofr kids,lego kids,cartoons about lego,lego cartoons',\n",
       "  'title': 'Lego City Police Lego Fireman Firetruck Cartoons about Lego for Children',\n",
       "  'upload_date': '2016-08-19 00:00:00',\n",
       "  'view_count': 167221.0}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_is_collab(text) -> bool:\n",
    "    keywords = [\"collab\", \"collaboration\", \"ft.\", \"feat\", \"featuring\"]\n",
    "    # Split the text into words and handle punctuation\n",
    "    text = text.lower()\n",
    "    words_in_text = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    \n",
    "    for word in keywords:\n",
    "        if word in words_in_text: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def video_is_collab(video) -> bool:\n",
    "    return (text_is_collab(video['title']) or text_is_collab(video['description']))\n",
    "\n",
    "def find_collab(text: str)->list[str]:\n",
    "    #print(\"good\")\n",
    "    pattern = r'@(\\w+)'\n",
    "    matches = re.findall(pattern, text) #what about ., !, ?\n",
    "    return matches\n",
    "\n",
    "def add_collab_ids(video):\n",
    "    vid_= video\n",
    "    #print(vid_)\n",
    "    vid_['collabs'] = set(find_collab(video['title']) + find_collab(video['description']))\n",
    "    #print(vid_)\n",
    "    #print(vid_['collabs'])\n",
    "    return vid_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after first filtering: 4  i.e  0.005509490096691551 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_collab_dataset = dataset.filter(video_is_collab)\n",
    "filtered_collab_count = filtered_collab_dataset.count()\n",
    "\n",
    "print(\"Number of rows after first filtering:\", filtered_collab_count, \" i.e \", filtered_collab_count/total_count * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after second filtering: 4  i.e  0.005509490096691551 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset_with_collab = filtered_collab_dataset.map(add_collab_ids).filter(lambda x : bool(x['collabs']))\n",
    "with_collab_count = dataset_with_collab.count()\n",
    "\n",
    "print(\"Number of rows after second filtering:\", with_collab_count, \" i.e \", with_collab_count/total_count * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_with_collab.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is now small enough so we can pandas it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "      <th>collabs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCctZfXbEF3TXc5TDGrbeo5A</td>\n",
       "      <td>2019-11-08 15:00:31.115495</td>\n",
       "      <td>Be sure to follow all the contributors on thei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KroY8uaabng</td>\n",
       "      <td>2832</td>\n",
       "      <td>298.0</td>\n",
       "      <td>QAnon,Q Anon,InTheMatrixxx,412 Anon,412Anon,We...</td>\n",
       "      <td>We The People Roundtable 00 - featuring @InThe...</td>\n",
       "      <td>2018-11-29 00:00:00</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>{InTheMatrixxx}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCOAjSDNYUSVX5NQUJ_KJGcQ</td>\n",
       "      <td>2019-10-31 22:01:56.978556</td>\n",
       "      <td>🔥 Mixtape Download Link : http://www.mediafire...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tdScjggrxIM</td>\n",
       "      <td>194</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HIPHOP,BEAT</td>\n",
       "      <td>[1st Mixtape 13:13]  02. hope (ft. Small Kidd,...</td>\n",
       "      <td>2018-11-21 00:00:00</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>{small, gmail, taeb_eat, ccthljlmtfck}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCMn3uPqSc7godHoN0o0mJqw</td>\n",
       "      <td>2019-11-07 10:55:06.926218</td>\n",
       "      <td>Featuring @ShaunRoig and @JeffreyPerezJr\\nPerf...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>g9O_7NGPycQ</td>\n",
       "      <td>34</td>\n",
       "      <td>413.0</td>\n",
       "      <td></td>\n",
       "      <td>When your friend is a Michael Jackson Sound Alike</td>\n",
       "      <td>2019-09-29 00:00:00</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>{ShaunRoig, JeffreyPerezJr}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaming</td>\n",
       "      <td>UC1zb8bU-vjW-bjOvkjmOSzQ</td>\n",
       "      <td>2019-11-19 01:39:27.257517</td>\n",
       "      <td>Subscribe if you enjoy! https://www.youtube.co...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fg_rlWY_9TM</td>\n",
       "      <td>460</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Madden,NFL,13,EA,Sports,Gameface,Connected,Car...</td>\n",
       "      <td>Madden 13: LeBron James To The NFL Ep. 4 - Hom...</td>\n",
       "      <td>2012-09-06 00:00:00</td>\n",
       "      <td>3444.0</td>\n",
       "      <td>{KingJames}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       categories                channel_id                  crawl_date  \\\n",
       "0  People & Blogs  UCctZfXbEF3TXc5TDGrbeo5A  2019-11-08 15:00:31.115495   \n",
       "1           Music  UCOAjSDNYUSVX5NQUJ_KJGcQ  2019-10-31 22:01:56.978556   \n",
       "2           Music  UCMn3uPqSc7godHoN0o0mJqw  2019-11-07 10:55:06.926218   \n",
       "3          Gaming  UC1zb8bU-vjW-bjOvkjmOSzQ  2019-11-19 01:39:27.257517   \n",
       "\n",
       "                                         description  dislike_count  \\\n",
       "0  Be sure to follow all the contributors on thei...            1.0   \n",
       "1  🔥 Mixtape Download Link : http://www.mediafire...            0.0   \n",
       "2  Featuring @ShaunRoig and @JeffreyPerezJr\\nPerf...            4.0   \n",
       "3  Subscribe if you enjoy! https://www.youtube.co...            2.0   \n",
       "\n",
       "    display_id  duration  like_count  \\\n",
       "0  KroY8uaabng      2832       298.0   \n",
       "1  tdScjggrxIM       194        36.0   \n",
       "2  g9O_7NGPycQ        34       413.0   \n",
       "3  fg_rlWY_9TM       460        38.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  QAnon,Q Anon,InTheMatrixxx,412 Anon,412Anon,We...   \n",
       "1                                        HIPHOP,BEAT   \n",
       "2                                                      \n",
       "3  Madden,NFL,13,EA,Sports,Gameface,Connected,Car...   \n",
       "\n",
       "                                               title          upload_date  \\\n",
       "0  We The People Roundtable 00 - featuring @InThe...  2018-11-29 00:00:00   \n",
       "1  [1st Mixtape 13:13]  02. hope (ft. Small Kidd,...  2018-11-21 00:00:00   \n",
       "2  When your friend is a Michael Jackson Sound Alike  2019-09-29 00:00:00   \n",
       "3  Madden 13: LeBron James To The NFL Ep. 4 - Hom...  2012-09-06 00:00:00   \n",
       "\n",
       "   view_count                                 collabs  \n",
       "0      3313.0                         {InTheMatrixxx}  \n",
       "1      2062.0  {small, gmail, taeb_eat, ccthljlmtfck}  \n",
       "2      5821.0             {ShaunRoig, JeffreyPerezJr}  \n",
       "3      3444.0                             {KingJames}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_with_collab = pd.DataFrame(dataset_with_collab.collect())\n",
    "display(df_with_collab)\n",
    "df_with_collab.to_csv('data/videos_with_collab_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'gmail', 'taeb_eat', 'ccthljlmtfck', 'JeffreyPerezJr', 'KingJames', 'ShaunRoig', 'InTheMatrixxx']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ats = list(set().union(*df_with_collab['collabs']))\n",
    "print(list(set().union(*df_with_collab['collabs'])))\n",
    "print(len(ats))\"\"\"\n",
    "from functools import reduce\n",
    "\n",
    "ats = list(reduce(set.union, df_with_collab['collabs'].tolist()))\n",
    "print(ats)\n",
    "print(len(ats))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/usernames_sample.jsonl', 'w') as jsonl_file:\n",
    "    json.dump(ats, jsonl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
