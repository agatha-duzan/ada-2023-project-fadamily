{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:01:58.756733850Z",
     "start_time": "2023-11-15T00:01:58.638941496Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:01:58.762612122Z",
     "start_time": "2023-11-15T00:01:58.760589560Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'climate change', 'global warming', 'greenhouse gases', 'rising sea levels',\n",
    "    'extreme weather', 'temperature increase', 'climate action', \n",
    "    'carbon emissions', 'renewable energy', 'sustainable living',\n",
    "    'climate science', 'climate crisis', 'climate adaptation',\n",
    "    'natural disaster', 'extreme heat', 'melting ice cap', 'sea level rise',\n",
    "    'biodiversity loss', 'deforestation', 'ocean acidification', 'climate policy', \n",
    "    'environmental policy',\n",
    "    'disaster recovery', 'climate refugees',\n",
    "    'carbon footprint', 'sustainable development', 'green technology',\n",
    "    'renewable resource', 'eco-friendly',\n",
    "    'ecosystem disruption', 'impact on climate',\n",
    "    'paris agreement', 'climate awareness',\n",
    "    'environmental justice', 'clean energy', 'zero carbon',\n",
    "    'green infrastructure', 'ozone layer',\n",
    "    'pollution', 'water scarcity', 'climate education'\n",
    "}\n",
    "\n",
    "keywords2 = {'olympics', 'olympic'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:01:58.783917243Z",
     "start_time": "2023-11-15T00:01:58.772273885Z"
    }
   },
   "outputs": [],
   "source": [
    "#check if text or tags contain climate keywords:\n",
    "#def idiot_filter(video):\n",
    "#    return video['upload_date'] > '2015'\n",
    "\n",
    "\n",
    "def about_climate(tags):\n",
    "    tags_set = set(tags)\n",
    "    return any(tag.strip().lower() in keywords2 for tag in tags_set)\n",
    "\n",
    "def climate_text(text):\n",
    "    lowercase_text = text.lower()\n",
    "    return any(keyword in lowercase_text for keyword in keywords2)\n",
    "\n",
    "def climate_related(video):\n",
    "    return (climate_text(video['title']) or about_climate(video['tags']) or climate_text(video['description']))\n",
    "    #return idiot_filter(video) and (climate_text(video['title']) or about_climate(video['tags']) or climate_text(video['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We read and filter the video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:02:01.467325882Z",
     "start_time": "2023-11-15T00:01:58.775437981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/15 08:01:59 WARN Utils: Your hostname, sebastien-Inspiron-7391-2n1 resolves to a loopback address: 127.0.1.1; using 192.168.1.73 instead (on interface wlp0s20f3)\n",
      "23/11/15 08:01:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/15 08:02:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:02:01.882525586Z",
     "start_time": "2023-11-15T00:02:01.470729565Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_disk = '/Volumes/Maxtor'\n",
    "path_to_disk_ubuntu = '/media/sebastien/Maxtor'\n",
    "file_path = '/yt_metadata_en.jsonl'\n",
    "\n",
    "raw_data = sc.textFile(path_to_disk_ubuntu + file_path)\n",
    "video_dataset = raw_data.map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:02:01.888262642Z",
     "start_time": "2023-11-15T00:02:01.886115854Z"
    }
   },
   "outputs": [],
   "source": [
    "#recent_videos = video_dataset.filter(idiot_filter)\n",
    "#climate_videos = recent_videos.filter(climate_related)\n",
    "climate_videos = video_dataset.filter(climate_related)\n",
    "#climate_videos_collected = climate_videos.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:02:01.893391515Z",
     "start_time": "2023-11-15T00:02:01.889138982Z"
    }
   },
   "outputs": [],
   "source": [
    "#climate_videos_path = \"data/climate_videos_new.jsonl\"\n",
    "\n",
    "#with jsonlines.open(climate_videos_path, \"w\") as jsonl_file:\n",
    "#    jsonl_file.write_all(climate_videos_collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we count the number of video uploaded each day\n",
    "\n",
    "This may be useful for our future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:12:15.077318575Z",
     "start_time": "2023-11-15T00:02:01.892166215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.            (710 + 8) / 2911]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebastien/miniconda3/envs/2023/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/sebastien/miniconda3/envs/2023/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/sebastien/miniconda3/envs/2023/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "[Stage 0:=============>                                        (711 + 8) / 2911]\r\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_videos_by_date = video_dataset.map(lambda x: (x[\"upload_date\"].split()[0], 1))\n",
    "\n",
    "# Group by date and count occurrences\n",
    "nb_videos_by_date = nb_videos_by_date.groupBy(lambda x: x[0]).map(lambda x: (x[0], len(x[1])))\n",
    "\n",
    "# Collect the result\n",
    "nb_videos_by_date_collected = nb_videos_by_date.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T00:12:15.079749290Z",
     "start_time": "2023-11-15T00:12:15.079020020Z"
    }
   },
   "outputs": [],
   "source": [
    "videos_by_date_path = \"data/nb_videos_by_date.jsonl\"\n",
    "with jsonlines.open(videos_by_date_path, \"w\") as jsonl_file:\n",
    "    jsonl_file.write_all(nb_videos_by_date_collected)\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
