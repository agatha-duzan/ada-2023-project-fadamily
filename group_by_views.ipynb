{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:54:23.432993103Z",
     "start_time": "2023-11-15T10:54:23.133867328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastien/miniconda3/envs/2023/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import pyspark.pandas\n",
    "from pyspark import SparkContext\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4428bd5c32c1f033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T10:54:26.340745960Z",
     "start_time": "2023-11-15T10:54:23.435933399Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/15 18:54:24 WARN Utils: Your hostname, sebastien-Inspiron-7391-2n1 resolves to a loopback address: 127.0.1.1; using 192.168.1.73 instead (on interface wlp0s20f3)\n",
      "23/11/15 18:54:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/15 18:54:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d1f25b70e749b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T10:54:26.719898387Z",
     "start_time": "2023-11-15T10:54:26.312385704Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_disk = '/Volumes/Maxtor'\n",
    "path_to_disk_ubuntu = '/media/sebastien/Maxtor'\n",
    "file_path = '/yt_metadata_en.jsonl'\n",
    "\n",
    "# pyspark_df = pyspark.pandas.read_json(path_to_disk_ubuntu + file_path)\n",
    "raw_data = sc.textFile(path_to_disk_ubuntu + file_path)\n",
    "video_dataset = raw_data.map(lambda x: json.loads(x))\n",
    "# video_dataset = sc.parallelize(raw_data.take(1000)).map(lambda x: json.loads(x))\n",
    "video_dataset = video_dataset.filter(lambda x: x['view_count'] is not None and x['upload_date'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9e4e3524b647d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T11:41:16.723472395Z",
     "start_time": "2023-11-15T10:54:26.723412470Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "views_per_date = video_dataset.map(lambda x: (x['upload_date'], x['view_count']))\n",
    "views_per_date = views_per_date.groupBy(lambda x: x[0]).map(lambda x: (x[0], len(x[1]), sum(map(lambda y: y[1], x[1])))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62f1ca17108d057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T11:41:17.698768049Z",
     "start_time": "2023-11-15T11:41:16.730387339Z"
    }
   },
   "outputs": [],
   "source": [
    "videos_by_date_path = \"data/nb_videos_and_views_by_date.jsonl\"\n",
    "with jsonlines.open(videos_by_date_path, \"w\") as jsonl_file:\n",
    "    jsonl_file.write_all(views_per_date)\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
