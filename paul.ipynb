{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:14:14.567039185Z",
     "start_time": "2023-12-22T20:14:14.385275936Z"
    }
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:14:14.616250578Z",
     "start_time": "2023-12-22T20:14:14.569033630Z"
    }
   },
   "outputs": [],
   "source": [
    "climate_videos_path = \"data/climate_videos_v3.jsonl\"\n",
    "all_sample_videos_path = \"data/sampled_dataset_1percent.jsonl\"\n",
    "#feather_path = \"data/yt_metadata_helper.feather\"\n",
    "nb_videos_by_cat_path = \"data/nb_videos_by_cat.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:14:14.618002870Z",
     "start_time": "2023-12-22T20:14:14.616112219Z"
    }
   },
   "outputs": [],
   "source": [
    "#video_dataset_feather = pd.read_feather(feather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-22T20:14:14.616383914Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#For statistics on the entire dataset, we use the sampled dataset which will not give exact results but will be statistically relevent\n",
    "all_videos_df = pd.read_json(all_sample_videos_path, lines=True)\n",
    "#all_videos_df = pd.read_feather(feather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#all_videos_df['upload_date'] = all_videos_df['upload_date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "climate_videos_df = pd.read_json(climate_videos_path, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the categories of Climate Related videos compared to overall youtube? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "climate_videos_df['categories'] = climate_videos_df['categories'].replace('', 'not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Coutning the number of videos in each category\n",
    "category_counts_climate = climate_videos_df['categories'].value_counts()\n",
    "category_counts_all = nb_videos_by_cat = pd.read_json(nb_videos_by_cat_path, lines=True)\n",
    "category_counts_all['categories'] = category_counts_all['categories'].replace('', 'not specified')\n",
    "category_counts_all = category_counts_all.set_index('categories').squeeze()\n",
    "categories = category_counts_climate.index\n",
    "\n",
    "fig = px.pie(category_counts_climate.reset_index(),\n",
    "             values='count',\n",
    "             names='categories',\n",
    "             title='Categories Distribution - Climate Change related Videos',\n",
    "             width=800,\n",
    "             height=800,\n",
    "             category_orders={\"categories\":categories.to_list()[::-1]})\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_traces( textinfo='percent+label', textposition='inside')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig = px.pie(category_counts_all.reset_index(),\n",
    "             values='count',\n",
    "             names='categories',\n",
    "             title='Categories Distribution - All Videos',\n",
    "             width=800,\n",
    "             height=800,\n",
    "             category_orders={\"categories\":categories.to_list()[::-1]})\n",
    "fig.update_traces(textinfo='percent+label', textposition='inside')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:09:41.564076892Z",
     "start_time": "2023-12-22T20:09:41.024575595Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mto_datetime(climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m evolution_category_counts_climate \u001b[38;5;241m=\u001b[39m (climate_videos_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby(\n\u001b[1;32m      4\u001b[0m                                                                     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39maggregate(\n\u001b[1;32m      5\u001b[0m                                                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39munstack(\n\u001b[1;32m      6\u001b[0m                                                                     fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mstack()\u001b[38;5;241m.\u001b[39mreset_index() \u001b[38;5;66;03m#add 0 values when there is no video in a category for a given time\u001b[39;00m\n\u001b[1;32m      9\u001b[0m evolution_category_counts_climate \u001b[38;5;241m=\u001b[39m evolution_category_counts_climate\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "climate_videos_df['quarter'] = pd.to_datetime(climate_videos_df['upload_date']).dt.to_period('Q')\n",
    "\n",
    "evolution_category_counts_climate = (climate_videos_df[['categories', 'quarter', 'display_id']].groupby(\n",
    "                                                                    ['categories', 'quarter']).aggregate(\n",
    "                                                                    'count')).unstack(\n",
    "                                                                    fill_value=0).stack().reset_index() #add 0 values when there is no video in a category for a given time\n",
    "\n",
    "\n",
    "evolution_category_counts_climate = evolution_category_counts_climate.rename(columns={'display_id': 'count'})\n",
    "evolution_category_counts_climate['quarter'] = evolution_category_counts_climate['quarter'].astype(str)\n",
    "\n",
    "fig = px.area(evolution_category_counts_climate.reset_index(), x=\"quarter\", y=\"count\", color=\"categories\", category_orders={\"categories\":categories.to_list()[::-1]})\n",
    "fig.show()\n",
    "\n",
    "total_counts = evolution_category_counts_climate.groupby('quarter')['count'].sum() #number of videos added per time unit\n",
    "evolution_category_counts_climate['proportion'] = evolution_category_counts_climate.apply(lambda row: row['count']/total_counts[row['quarter']], axis=1)\n",
    "\n",
    "fig = px.area(evolution_category_counts_climate.reset_index(), x=\"quarter\", y=\"proportion\", color=\"categories\", category_orders={\"categories\":categories.to_list()[::-1]})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this category analysis we choose some relevent categories (thos with more than 1000 videos related to climate change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:08:53.786516067Z",
     "start_time": "2023-12-22T20:08:53.261149183Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_counts_climate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m relevent_cat \u001b[38;5;241m=\u001b[39m \u001b[43mcategory_counts_climate\u001b[49m[category_counts_climate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      2\u001b[0m relevent_cat \u001b[38;5;241m=\u001b[39m relevent_cat\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category_counts_climate' is not defined"
     ]
    }
   ],
   "source": [
    "relevent_cat = category_counts_climate[category_counts_climate > 1000].reset_index()\n",
    "relevent_cat = relevent_cat.drop(columns = ['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding if a video is climate change related in all_videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:08:56.679865379Z",
     "start_time": "2023-12-22T20:08:56.643608202Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'climate_videos_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlike_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdislike_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m obs_study_climate_videos_df \u001b[38;5;241m=\u001b[39m \u001b[43mclimate_videos_df\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlike_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdislike_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m obs_study_climate_videos_df \u001b[38;5;241m=\u001b[39m obs_study_climate_videos_df[(obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      5\u001b[0m                                                           (obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlike_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview_count\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      6\u001b[0m                                                           (obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdislike_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview_count\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      8\u001b[0m obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(obs_study_climate_videos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'climate_videos_df' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['categories', 'month', 'view_count', 'display_id', 'like_count', 'dislike_count']\n",
    "\n",
    "obs_study_climate_videos_df = climate_videos_df.dropna(subset=['view_count', 'like_count', 'dislike_count'])\n",
    "obs_study_climate_videos_df = obs_study_climate_videos_df[(obs_study_climate_videos_df['view_count'] > 0) &\n",
    "                                                          (obs_study_climate_videos_df['like_count'] <= obs_study_climate_videos_df['view_count']) &\n",
    "                                                          (obs_study_climate_videos_df['dislike_count'] <= obs_study_climate_videos_df['view_count'])]\n",
    "\n",
    "obs_study_climate_videos_df['month'] = pd.to_datetime(obs_study_climate_videos_df['upload_date']).dt.to_period('M')\n",
    "obs_study_climate_videos_df['is_climate'] = 1\n",
    "\n",
    "all_videos_df['categories'] = all_videos_df['categories'].replace('', 'not specified')\n",
    "\n",
    "obs_study_all_videos_df = all_videos_df.dropna(subset=['view_count', 'like_count', 'dislike_count'])\n",
    "obs_study_all_videos_df = obs_study_all_videos_df[(obs_study_all_videos_df['view_count'] > 0) &\n",
    "                                                (obs_study_all_videos_df['like_count'] <= obs_study_all_videos_df['view_count']) &\n",
    "                                                (obs_study_all_videos_df['dislike_count'] <= obs_study_all_videos_df['view_count'])]\n",
    "\n",
    "obs_study_all_videos_df['month'] = pd.to_datetime(obs_study_all_videos_df['upload_date']).dt.to_period('M')\n",
    "\n",
    "\n",
    "obs_study_all_videos_df = obs_study_all_videos_df.merge(obs_study_climate_videos_df,how='left', on=obs_study_all_videos_df.columns.to_list())\n",
    "obs_study_all_videos_df['is_climate'] = obs_study_all_videos_df['is_climate'].fillna(0)\n",
    "\n",
    "obs_study_non_climate_videos_df = obs_study_all_videos_df[obs_study_all_videos_df['is_climate'] == 0]\n",
    "\n",
    "columns = columns + ['is_climate']\n",
    "\n",
    "obs_study_climate_videos_df = obs_study_climate_videos_df[columns]\n",
    "obs_study_non_climate_videos_df = obs_study_all_videos_df[columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different view counts ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_df = obs_study_climate_videos_df.merge(right = obs_study_non_climate_videos_df,\n",
    "                                                on = ['categories', 'month'],\n",
    "                                                suffixes=('_climate', '_non_climate'))\n",
    "\n",
    "matching_df = matching_df.groupby(['categories','display_id_climate', 'view_count_climate', 'is_climate_climate']).agg({\n",
    "    'view_count_non_climate' : 'mean' ,\n",
    "    'display_id_non_climate' : (lambda x : \",\".join(x)),\n",
    "    'is_climate_non_climate' : (lambda x : 0)\n",
    "}\n",
    ").reset_index()\n",
    "\n",
    "matching_df = matching_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_matched = matching_df[['categories','display_id_climate', 'view_count_climate', 'is_climate_climate']]\n",
    "cols = ['categories','display_id', 'view_count', 'is_climate']\n",
    "\n",
    "climate_matched = climate_matched.rename(columns = {old : new for old,new in zip(climate_matched.columns, cols)})\n",
    "\n",
    "non_climate_matched = matching_df[['categories','display_id_non_climate', 'view_count_non_climate', 'is_climate_non_climate']]\n",
    "non_climate_matched = non_climate_matched.rename(columns = {old : new for old,new in zip(non_climate_matched.columns, cols)})\n",
    "\n",
    "\n",
    "obs_study_df = pd.concat([climate_matched,non_climate_matched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(obs_study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "intercepts = []\n",
    "coefficients = []\n",
    "intercept_pvals = []\n",
    "coefficient_pvals = []\n",
    "coef_colors = []\n",
    "\n",
    "for category in relevent_cat['categories']:\n",
    "    # Fit the model for each category\n",
    "    model = smf.ols(formula='view_count ~ is_climate', data=obs_study_df[obs_study_df['categories'] == category])\n",
    "    result = model.fit()\n",
    "    \n",
    "    print(result.summary())\n",
    "\n",
    "    # Retrieve the intercept and coefficient\n",
    "    intercept, coef = result.params\n",
    "    \n",
    "    # Check p-values for statistical relevance\n",
    "    intercept_p, coef_p = result.pvalues\n",
    "    \n",
    "    # Determine if values are statistically relevant\n",
    "    intercept_val = \"Not statistically relevant\" if intercept_p >= 0.05 else intercept\n",
    "    coef_val = \"Not statistically relevant\" if coef_p >= 0.05 else coef\n",
    "    \n",
    "    # Store the results and color\n",
    "    categories.append(category)\n",
    "    intercepts.append(intercept)\n",
    "    coefficients.append(coef)\n",
    "    intercept_pvals.append(intercept_p)\n",
    "    coefficient_pvals.append(coef_p)\n",
    "\n",
    "print(coefficient_pvals)\n",
    "\n",
    "sizes = [100 for _ in range(len(categories))] # Replace with actual values representing the size of each bubble\n",
    "\n",
    "# Create the bubble plot\n",
    "plt.scatter(categories, coefficients, s = sizes ,alpha=0.5)  # 's' determines the size of each bubble\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Bubble Plot of is_climate Coefficient per Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Coefficient of is_climate')\n",
    "plt.axhline(0, color='grey', lw=0.5)  # Add a line at y=0 for reference\n",
    "plt.xticks(rotation=25)  # Rotate category names for better readability\n",
    "\n",
    "# Optional: Add a color scale or other features to represent additional dimensions\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust the layout for a better fit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "- Different predominant categories, as expected\n",
    "- Main for climate change: N&P, Education, Science & Tech "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We study like/dislikes comparison metrics**\n",
    "\n",
    "\n",
    "$$SLDR(N_{like}, N_{dislike}) =  (-1)^{\\delta} \\dfrac{\\max{(N_{like} , N_{dislike}) + 1}}{\\min{(N_{like} , N_{dislike} ) +1 } }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_study_climate_videos_df = obs_study_climate_videos_df.sort_values('view_count')\n",
    "obs_study_climate_videos_df['view_count'] = obs_study_climate_videos_df['view_count'].astype(int)\n",
    "obs_study_climate_videos_df['view_count_climate'] = obs_study_climate_videos_df['view_count']\n",
    "\n",
    "obs_study_non_climate_videos_df = obs_study_non_climate_videos_df.sort_values('view_count')\n",
    "obs_study_non_climate_videos_df['view_count'] = obs_study_non_climate_videos_df['view_count'].astype(int)\n",
    "obs_study_non_climate_videos_df['view_count_non_climate'] = obs_study_non_climate_videos_df['view_count']\n",
    "\n",
    "not_matched_climate_videos_df = obs_study_climate_videos_df #climate videos who were not matched (all of them for now)\n",
    "not_matched_non_climate_videos_df = obs_study_non_climate_videos_df #non climate videos who were not matched (all of them for now)\n",
    "\n",
    "matching_df = pd.DataFrame()\n",
    "\n",
    "print(not_matched_climate_videos_df.shape[0])\n",
    "\n",
    "while not_matched_climate_videos_df.shape[0] > 0: #purpose is to matched as many climate videos as possible\n",
    "\n",
    "    not_matched_climate_videos_df = not_matched_climate_videos_df.sort_values('view_count') #sorting to be able to use merge_asof\n",
    "    not_matched_non_climate_videos_df = not_matched_non_climate_videos_df.sort_values('view_count')\n",
    "\n",
    "\n",
    "    matching_2_df = pd.merge_asof(\n",
    "                                left = not_matched_climate_videos_df,\n",
    "                                right = not_matched_non_climate_videos_df, \n",
    "                                on='view_count', #nearest match on view count\n",
    "                                by=['categories', 'month'], #exact match on categories and month\n",
    "                                suffixes=('_climate', '_non_climate'), direction = 'nearest')\n",
    "    \n",
    "    matching_2_df['relative_diff'] = (matching_2_df['view_count_climate'] - matching_2_df['view_count_non_climate']).abs()/matching_2_df[['view_count_non_climate', 'view_count_climate']].max(axis=1)\n",
    "                                            #view_count relative differences in the match we found\n",
    "    \n",
    "    #allowing only matches with samll enough view count relative_diff\n",
    "    matching_2_df = matching_2_df.sort_values('relative_diff')\n",
    "    matching_2_df = matching_2_df[matching_2_df['relative_diff'] < 0.1]\n",
    "\n",
    "    #Since several_climate_videos may have been matched with a single non_climate_videos, we only keep the best match for each duplicates \n",
    "    matching_2_df_filtered = matching_2_df.drop_duplicates(subset = 'display_id_non_climate', keep ='first')\n",
    "\n",
    "    #not matched dfs are updated: climate_videos who were droped when we droped the duplicates above.\n",
    "    not_matched_climate_videos_df = not_matched_climate_videos_df[~not_matched_climate_videos_df['display_id'].isin(matching_2_df_filtered['display_id_climate'])\n",
    "                                                            & not_matched_climate_videos_df['display_id'].isin(matching_2_df['display_id_climate'])]\n",
    "    #non_climate_videos who were not yet used for a match\n",
    "    not_matched_non_climate_videos_df = not_matched_non_climate_videos_df[~not_matched_non_climate_videos_df['display_id'].isin(matching_2_df['display_id_non_climate'])]\n",
    "    \n",
    "    print(not_matched_climate_videos_df.shape[0])\n",
    "\n",
    "    #updating the matching\n",
    "    matching_df = pd.concat([matching_df, matching_2_df_filtered])\n",
    "\n",
    "climate_ids = matching_df['display_id_climate']\n",
    "non_climate_ids = matching_df['display_id_non_climate']\n",
    "matching_df = matching_df.drop(columns= ['view_count', 'relative_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(matching_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_cols = [name for name in matching_df.columns if 'non_climate' not in name]\n",
    "non_climate_cols = ['categories','month'] +  [name for name in matching_df.columns if 'non_climate'  in name]\n",
    "\n",
    "climate_matched = matching_df[climate_cols]\n",
    "climate_matched = climate_matched.rename(columns = {old : new for old,new in zip(sorted(climate_matched.columns), sorted(columns))})\n",
    "\n",
    "non_climate_matched = matching_df[non_climate_cols]\n",
    "non_climate_matched = non_climate_matched.rename(columns = {old : new for old,new in zip(sorted(non_climate_matched.columns), sorted(columns))})\n",
    "\n",
    "obs_study_df = pd.concat([climate_matched,non_climate_matched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sldr(like_count, dislike_count):\n",
    "    mask = (like_count == 0) & (dislike_count == 0)\n",
    "    result = np.where(\n",
    "        mask,\n",
    "        1,\n",
    "        np.where(\n",
    "            like_count > dislike_count,\n",
    "            (like_count + 1) / (dislike_count + 1),\n",
    "            - (dislike_count + 1) / (like_count + 1)\n",
    "        )\n",
    "    )\n",
    "    return result\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_study_df['like_prop'] = obs_study_df['like_count']/obs_study_df['view_count'] * 100\n",
    "obs_study_df['dislike_prop'] = obs_study_df['dislike_count']/obs_study_df['view_count'] * 100\n",
    "obs_study_df['engagement_rate'] = obs_study_df['like_prop'] + obs_study_df['dislike_prop']\n",
    "obs_study_df['sldr'] = sldr(obs_study_df['like_count'], obs_study_df['dislike_count']) \n",
    "obs_study_df['dislike_to_like'] = np.where(\n",
    "                    (obs_study_df['like_count'] == 0) & (obs_study_df['dislike_count'] == 0),\n",
    "                    0.5,\n",
    "                    obs_study_df['dislike_count']/(obs_study_df['like_count'] + obs_study_df['dislike_count'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorie in relevent_cat['categories']:\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(categorie)\n",
    "    print(\"\\n\")    \n",
    "    model=smf.ols(formula='dislike_to_like ~ is_climate',data=obs_study_df[obs_study_df['categories'] == categorie])\n",
    "    result=model.fit()\n",
    "\n",
    "    print(result.summary())\n",
    "\n",
    "    # Scatter plot with regression line\n",
    "    sns.lmplot(x='is_climate', y='dislike_to_like', data=obs_study_df, ci=None)\n",
    "    plt.title('Scatter Plot with Regression Line')\n",
    "    plt.xlabel('Is Climate')\n",
    "    plt.ylabel('Engagement Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(5, 6))\n",
    "fig.subplots_adjust(hspace=0.1)  # adjust space between axes\n",
    "\n",
    "# plot the same data on both axes\n",
    "ax1.boxplot([climate_videos_df['sldr'].dropna(), video_dataset_feather['sldr'].dropna()], showfliers=False)\n",
    "ax2.boxplot([climate_videos_df['sldr'].dropna(), video_dataset_feather['sldr'].dropna()], showfliers=False)\n",
    "\n",
    "# zoom-in / limit the view to different portions of the data\n",
    "ax1.set_title('SLDR Distribution')\n",
    "ax1.set_ylim(1, 70)  # outliers only\n",
    "y_ticks_high = list(range(1, 70, 10))\n",
    "y_ticks_high.append(1)\n",
    "ax1.set_yticks(y_ticks_high)  # Set y-axis ticks\n",
    "\n",
    "ax2.set_ylim(-40, -1)  # most of the data\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "y_ticks_low  = list(range(-40, 0, 10))\n",
    "y_ticks_low.append(-1)\n",
    "ax2.set_yticks(y_ticks_low)\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "#ax1.text(1, climate_mean, f\"Mean: {climate_mean:.2f}\", ha='center', va='bottom', color='red')\n",
    "#ax1.text(2, all_mean, f\"Mean: {all_mean:.2f}\", ha='center', va='bottom', color='red')\n",
    "\n",
    "ax1.set_xticklabels(['','','Climate Videos', 'All Videos'])\n",
    "\n",
    "# Now, let's turn towards the cut-out slanted lines.\n",
    "# We create line objects in axes coordinates, in which (0,0), (0,1),\n",
    "# (1,0), and (1,1) are the four corners of the axes.\n",
    "# The slanted lines themselves are markers at those locations, such that the\n",
    "# lines keep their angle and position, independent of the axes size or scale\n",
    "# Finally, we need to disable clipping.\n",
    "\n",
    "d = 0  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'SLDR' column to numeric type\n",
    "climate_sldr_plot = pd.to_numeric(climate_videos_df['sldr'].dropna())\n",
    "all_sldr_plot = pd.to_numeric(all_videos_df['sldr'].dropna())\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=[climate_sldr_plot, all_sldr_plot],\n",
    "    palette=\"Set3\",\n",
    "    showfliers=False\n",
    ")\n",
    "plt.ylim(-40, 85)\n",
    "plt.title('Comparison of SLDR between Climate Videos and All Videos')\n",
    "plt.xticks([0, 1], ['Climate Videos', 'All Videos'])\n",
    "plt.ylabel('SLDR')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the like ratio is lower for climate videos. Hence they are more dabatable. And it goes much lower...\n",
    "\n",
    "Let's now study by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))  # Adjust the figure size as desired\n",
    "\n",
    "num_categories = len(categories)\n",
    "num_columns = num_categories // 4  # Number of columns in the subplot grid\n",
    "num_rows = num_categories // 4   # Number of rows in the subplot grid\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    ndlis_all = all_videos_df.query(f\"categories == '{category}'\")['sldr'].dropna()\n",
    "    ndlis_climate = climate_videos_df.query(f\"categories == '{category}'\")['sldr'].dropna()\n",
    "    \n",
    "    plt.boxplot([ndlis_all, ndlis_climate], showfliers=False)\n",
    "    \n",
    "    plt.xlabel('Videos')\n",
    "    plt.ylabel('sldr')\n",
    "    plt.title(f'Box Plot of SLDR for {category}')\n",
    "    \n",
    "    plt.grid(axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Add x labels\n",
    "    plt.xticks([1, 2], ['All Videos', 'Climate Videos'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [climate_videos_df, all_videos_df]:\n",
    "    df['upload_date'] = pd.to_datetime(df['upload_date'])\n",
    "    df['year_month'] = df['upload_date'].dt.to_period('Y')\n",
    "    average_like_ratio = df.groupby('year_month')['sldr'].mean()\n",
    "    average_like_ratio.plot(kind='line', figsize=(10, 6))\n",
    "\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Average SLDR')\n",
    "plt.title('Average SLDR Over Time')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(['Climate Videos', 'All Videos'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "plt.boxplot([all_videos_df['engagement_rate'].dropna(),climate_videos_df['engagement_rate'].dropna()], showfliers=False)\n",
    "plt.ylabel('Engagement Rate')\n",
    "plt.title('Box Plot of Engagement Rate') \n",
    "#plt.grid(axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "# Add x labels\n",
    "plt.xticks([1, 2], ['All Videos', 'Climate Videos'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))  # Adjust the figure size as desired\n",
    "\n",
    "num_categories = len(categories)\n",
    "num_columns = num_categories // 4  # Number of columns in the subplot grid\n",
    "num_rows = num_categories // 4   # Number of rows in the subplot grid\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    engagement_rate_all = all_videos_df.query(f\"categories == '{category}'\")['engagement_rate'].dropna()\n",
    "    engagement_rate_climate = climate_videos_df.query(f\"categories == '{category}'\")['engagement_rate'].dropna()\n",
    "    \n",
    "    plt.boxplot([engagement_rate_all, engagement_rate_climate], showfliers=False)\n",
    "    plt.ylabel('Engagement Rate')\n",
    "    plt.title(category)\n",
    "    \n",
    "    plt.grid(axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Add x labels\n",
    "    plt.xticks([1, 2], ['All Videos', 'Climate Videos'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "plt.boxplot([all_videos_df['like_percentage'].dropna(), climate_videos_df['like_percentage'].dropna()], showfliers=False)\n",
    "plt.ylabel('Like Percentage')\n",
    "plt.title('Box Plot of Like Percentage') \n",
    "#plt.grid(axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "# Add x labels\n",
    "plt.xticks([1, 2], ['All Videos', 'Climate Videos'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))  # Adjust the figure size as desired\n",
    "\n",
    "num_categories = len(categories)\n",
    "num_columns = num_categories // 4  # Number of columns in the subplot grid\n",
    "num_rows = num_categories // 4   # Number of rows in the subplot grid\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.subplot(num_rows, num_columns, i+1)\n",
    "    \n",
    "    like_percentage_all = all_videos_df.query(f\"categories == '{category}'\")['like_percentage'].dropna()\n",
    "    like_percentage_climate = climate_videos_df.query(f\"categories == '{category}'\")['like_percentage'].dropna()\n",
    "    \n",
    "    plt.boxplot([like_percentage_all, like_percentage_climate], showfliers=False)\n",
    "    plt.ylabel('Like Percentage')\n",
    "    plt.title(category)\n",
    "    \n",
    "    plt.grid(axis='y', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Add x labels\n",
    "    plt.xticks([1, 2], ['All Videos', 'Climate Videos'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climate concerned people growing, but climato skeptical vids ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
